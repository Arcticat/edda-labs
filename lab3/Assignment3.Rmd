---
  title: "Assignment 3"
  author: "Andrea Di Dio, Chenghan Song, Jiacheng Lu --- Group 22"
  fontsize: 10pt
  output:
    pdf_document: default
    html_document: default
---
## Exercise 1
#### a)
First add loglongevity to the dataframe. We draw plots to show the graphical summary of the data. 
$H_0:$ The sexual activity does not affect longevity.
```{r}
data=read.table(file="fruitflies.txt",header=TRUE)
fruitflies=data.frame(data)
fruitflies$loglongevity=log(fruitflies$longevity,exp(1))
plot(fruitflies$longevity~fruitflies$thorax,pch=as.character(fruitflies$activity),main="Informative plot")
par(mfrow=c(1,2))
boxplot(fruitflies$longevity~fruitflies$activity,data=fruitflies,xlab="sexual activity",ylab="longevity",main="boxplot of longevity against activity")
stripchart(fruitflies$longevity~fruitflies$activity,vertical=TRUE)
fruitfliesaov=lm(loglongevity~activity,data=fruitflies)
anova(fruitfliesaov)
summary(fruitfliesaov)
```
The p-value for testing $H_0$ is smaller than 0.05, thus we reject $H_0$. Which means regardless of thorax, sexual activity influences longevity. Use confidence interval to estimate longevity. For high sexual activity, estimated longevity is 36.68; for isolated activity, longevity is between 61.52; for low sexual activity, longevity is between 54.59.


#### b)
$H_0$:The sexual activity does not affect longevity.
```{r}
fruitfliesaov2=lm(loglongevity~thorax+activity,data=fruitflies)
drop1(fruitfliesaov2,test="F")
```
The p-value for testing $H_0$ is smaller than 0.05, thus we reject $H_0$. Which means Taking thorax into consideration, sexual activity still has an influence on longevity.
```{r}
fruitfliesaov3=lm(loglongevity~thorax+activity,data=fruitflies)
summary(fruitfliesaov3)
mean(fruitflies$thorax)
```
From the result of the test, we can find out that $alpha_{1}<alpha_{3}<alpha_{2}$, which means sexual activity decrease longevity. According to the model, So longevity for isolated sexual activity is $e^{Y_{isolated}} = e^{4.09}=59.45$. Longevity for low is $e^{Y_{low}} = e^{3.96}=52.50$.
Longevity for high is $e^{Y_{high}} = e^{3.68}=39.46$.

#### c)
$H_0:\mu_{isolated}=\mu_{high}$.
$H_0:\mu_{low}=\mu_{high}$.
```{r}
plot(loglongevity~thorax,pch=unclass(fruitflies$activity),data=fruitflies)
abline(lm(loglongevity~thorax,data=fruitflies[c(1:25),]))
abline(lm(loglongevity~thorax,data=fruitflies[c(26:50),]))
abline(lm(loglongevity~thorax,data=fruitflies[c(51:75),]))
aovfruitfliesinter=lm(loglongevity~activity*thorax,data=fruitflies)
summary(aovfruitfliesinter)
```
From the test result, p-value for $H_0:\mu_{isolated}=\mu_{high}$ is 0.0545 and for $H_0:\mu_{low}=\mu_{high}$ is 0.2771, both bigger than 0.05. Thus we do not reject them. In the plot we can see that the lines can be parallel. So, the dependence is similar under three conditions of sexual activity.

#### d)
We think the analyses with thorax length is better because from the test result in c) we can see that thorax length does influence longevity, so a)'s model does not meet the assumption of ANoVA, so we should take thorax length into consideration.


#### e)
```{r}
qqnorm(residuals(fruitfliesaov2),main="normal QQ-plot of the residuals")
plot(fitted(fruitfliesaov2),residuals(fruitfliesaov2),main=" residuals versus fitted plot")
```
From the normal qq plot of the residuals we can see that the spread is not normal. The plot of residuals versus fitted plot does not show any pattern which means no heteroscedasticity.


#### f)
```{r}
fruitflies$activity=as.factor(fruitflies$activity)
fruitfliesaov4=lm(longevity~thorax+activity,data=fruitflies)
qqnorm(residuals(fruitfliesaov4),main="normal QQ-plot of the residuals")
plot(fitted(fruitfliesaov4),residuals(fruitfliesaov4),main=" residuals versus fitted plot")
```
If we use longevity rather than its logarithm, from the plot we can see that the residuals versus fittede plot shows a certain pattern: with the growth of fitted, the redisuals' range grows bigger. Comparing with logarithm as response, it is clear that logarithm is much better.


## Exercise 2

#### a)

```{r}
psi_raw <- read.delim("./psi.txt", header = TRUE, sep = "")
psi_yes <- psi_raw[which(psi_raw$psi == 1),]
psi_no <- psi_raw[which(psi_raw$psi == 0),]
passed <- psi_raw[which(psi_raw$passed == 1),]
not_passed <- psi_raw[which(psi_raw$passed == 0),]
boxplot(psi_raw$gpa, passed$gpa, not_passed$gpa, names = c("GPA","GPA of passed","GPA of not passed"),
        main = "Boxplot to compare GPAs (passed/not passed)")
```

The boxplot above shows the comparison among the total GPA of the students, the GPA for the students who passed the assignments and the GPA for the students that did not pass the assignment. The boxplot shows that the median GPA of the students who passed the assignment is higher than that of the students who didn't pass regardless of the teaching method. This could mean that the GPA of a student is a significant factor to the outcome of an assignment for the students.

```{r}
boxplot(psi_raw$gpa, psi_yes$gpa, psi_no$gpa, names = c("GPA", "GPA of psi", "GPA of no-psi"),
        main = "Boxplot to compare GPAs (with/without psi)")
```

The boxplot above shows the comparison among the total GPA of the students, the GPA for the students who were taught using _psi_ and the GPA for the students who were taught using the traditional method. It shows that the median GPA of a student who has been taught with _psi_ is marginally higher than that of the students who were taught using the traditional method. This could mean that the teaching method does not necessarily influence the GPA for a student.

```{r}
par(mfrow = c(1,3))
qqnorm(psi_raw$gpa, main = "QQ plot of GPA");qqline(psi_raw$gpa)
qqnorm(psi_yes$gpa, main = "QQ plot of GPA (psi)");qqline(psi_yes$gpa)
qqnorm(psi_no$gpa, main = "QQ plot of GPA (no psi)");qqline(psi_no$gpa)
```

The QQ-plots above compare the population distribution of the GPA among all students, the students who received _psi_ and the students who were taught using the traditional method. The only QQ-plot which might indicate normality of the population is the one showing the GPA for the students who have been taught with the _psi_ method whilst the other two plots don't seem to be sampled from a normal distribution. This might be a problem given that the sample population of the data for students taught with _psi_ and those taught with the traditional method seems to be different making the experiment less fair or significant.

```{r}
psi_passed_tab <- xtabs(~psi_raw$passed + psi_raw$psi)
rownames(psi_passed_tab) <- c("Passed", "Not Passed")
colnames(psi_passed_tab) <- c("No psi", "psi")
ftable(psi_passed_tab)
```

The contingency table above shows that the teaching method might have an influence (ignoring that students might have been sampled from different populations) on whether a students passes the assignment or not. Most students who have not been taught with _psi_ have not passed the assignment, and the students who have been treated with _psi_ have passed the assignment in a higher number than students who have been taught with the traditional method.

#### b)

$H_0:$ Using _psi_ does not affect whether a student passes the assignment or not.

```{r}
psi_glm <- glm(psi_raw$passed ~ psi_raw$psi + psi_raw$gpa, family = binomial)
print(summary(psi_glm)$coefficients)
```

The p-value for _psi_ is $0.025 < \alpha$ meaning that we can safely reject $H_0$ concluding that the _psi_ usage has an effect on the student's ability to pass the assignment. In addition, the positive sign for the parameter estimate for _psi_ ($= 2.338$) also means that when _psi_ is used, the linear predictor is increased by the parameter estimate, increasing the odds of passing the assignment by $e^{2.338} = 10.36$.

#### c)

In order to estimate the probabilities, we assume the model $Pr(Y = 1) = \Psi(\mu + \alpha + \beta X)$ and by extrapolating the coefficients from the summary in _b)_ we can use the logistic function $\Psi(x) = \frac{1}{1 + e^{-x}}$.\newline

To find the probability that a student passes the assignment if it has **received** _psi_ and a gpa of 3 we use:

$x = -11.602 + (2.338 * 1) + (3.063 * 3) \rightarrow x = -0.075 \rightarrow p = \frac{1}{1 + e^{0.075}} = 0.481$

To find the probability of a student passing **without** _psi_ and a gpa of 3, we use:

$x = -11.602 + (2.338 * 0) + (3.063 * 3) \rightarrow x = -11.602 + (3.063 * 3) \rightarrow x = -2.41 \rightarrow p = \frac{1}{1 + e^{2.41}} = 0.082$

#### d)

As shown in _b)_, using _psi_ increases the linear predictor by 2.338 and hence increases the odds of passing the assignment by a factor $e^{2.338} = 10.36$. This means that a student which has been taught using the _psi_ method is 10.36 times more likely to pass the assignment than a student who has been taught using the standard method. Given that _gpa_ is an independent variable, this number does **not** depend on the gpa of a student.

#### e)

$H_0:$ The probability of success of students receiving the _psi_ method is the same as that of students who get the traditional method.

```{r}
x <- matrix(c(3, 15, 8, 6), 2, 2)
fisher.test(x)
```

15 represents the number of students who did not receive _psi_ and did **not** show improvement. 6 is the number of students who received _psi_ but did **not** show improvement. The _Fisher's exact test_ reports a p-value of $0.0265 < \alpha$ meaning that we can safely reject $H_0$ concluding that there is a significant difference in the probabilities of success for the two different teaching methods and that the _psi_teaching method seems to work.

#### f)

By studying and analysing the data in _a)_, we have found that the GPA of a student seems to affect also the passing rate of the students. Seeing that the Fisher's exact test for this contingency table does not take it into account, we think that this approach is **wrong**. 

#### g)

* Fisher's exact test is good and accurate (_exact_) for small datasets, especially for 2x2 contingency tables like the one we have.
* It is hard to make predictions with Fisher's exact test, whilst the logistic regression model gives us the coefficients which are useful for making predictions as we did in _c)_.
* Fisher's exact test gives us a more precise p-value to test our null hypotheses compared to that retrieved using the logisitc regression.


## Exercise 3

##### a)

```{r}
afrdata=read.table(file="africa.txt",header=TRUE);
pairs(afrdata);
afrdataglm=glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec+numregim, family=poisson,data=afrdata);
summary(afrdataglm)[12];
```
```{r}
confint(afrdataglm)
```


$H_0$: The explanatory variable does not have a main effect on the number of successful military coups from independence to 1989.

The p-value for oligarchy is 0.035 meaning that we can safely reject $H_0$ concluding that number years country ruled by military oligarchy from independence to 1989 has a significant effect on the number of successful military coups from independence to 1989. We are 95% confident that the mean number of successful military coups from independence to 1989 increases between 0.5% and 14% for each additional year country ruled by military oligarchy.

The p-value for pollib is 0.0089 meaning that we reject $H_0$ concluding that political liberalization has an effect on the number of successful military coups from independence to 1989. We are 95% confident that the mean number of successful military coups from independence to 1989 decreases between 18% and 126% for each level the political liberalization increases. 

The p-value for parties is 0.00595 meaning that we can safely reject $H_0$ concluding that number of legal political parties in 1993 has a significant effect on the number of successful military coups from independence to 1989. We are 95% confident that the mean number of successful military coups from independence to 1989 increases between 0.8% and 5% for each additional increase of legal political parties in 1993.

```{r}
par(mfrow=c(2,2));
plot(fitted(afrdataglm),residuals(afrdataglm),main="residuals VS fitted values");plot(log(fitted(afrdataglm)),residuals(afrdataglm),main="residuals VS log fitted values");
plot(log(fitted(afrdataglm)),residuals(afrdataglm,type="response"),main="response residuals VS fitted values")
```

From the plots above we can see some specific patterns which means the model does not fit in this case. 

##### b)
```{r}
summary(glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec+numregim,data=afrdata))[12]
```

```{r}
summary(glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec,data=afrdata))[12]
```
```{r}
summary(glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size,data=afrdata))[12]
```
```{r}
summary(glm(miltcoup~oligarchy+pollib+parties+popn+size,data=afrdata))[12]
```
```{r}
summary(glm(miltcoup~oligarchy+pollib+parties+popn,data=afrdata))[12]
```

```{r}
summary(glm(miltcoup~oligarchy+pollib+parties,data=afrdata))[12]
```
By using the step down approach, we find that oligarchy, pollib, and parties are the essential in explaining the number of successful military coups from independence to 1989. Other explanatory variables:pctvote, popn, size, numelec, and numregim should be removed.

The resulting model of the step-down method is: miltcoup = 1.62597 + 0.15261 $*$ oligarchy - 0.95419 $*$ pollib + 0.04239 $*$ parties + error
